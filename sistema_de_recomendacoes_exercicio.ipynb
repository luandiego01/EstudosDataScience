{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Exercício: Sistemas de Recomendação\n",
    "\n",
    "<br>\n",
    "\n",
    "__Introdução: o objetivo deste exercício é discutirmos uma metodologia de avaliação de filtros colaborativos.__\n",
    "\n",
    "<br>\n",
    "\n",
    "Para isso, utilize a função getData() para carregar os dados: \n",
    "\n",
    "    - teremos avaliações que 367 usuários fizeram a respeito de 80 filmes. As notas variam entre 1, 2, 3, 4, e 5. \n",
    "    \n",
    "    - os valores NaN representam filmes que ainda não foram avaliados pelos usuários.\n",
    "\n",
    "Como __modelo__ para as recomendações, usaremos a __fatoração matricial.__ Use a classe MatrixFactorization() construída ao longo do módulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('u.data', sep='\\t', names=r_cols,\n",
    "                          encoding='latin-1')\n",
    "    m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "    movies = pd.read_csv('u.item', sep='|', names=m_cols, usecols=range(5),\n",
    "                         encoding='latin-1')\n",
    "    movie_ratings = pd.merge(movies, ratings)\n",
    "    temp = movie_ratings[['movie_id', 'user_id', 'rating']].copy()\n",
    "    temp = temp.pivot_table(columns='movie_id', index='user_id', values='rating').copy()\n",
    "    temp.index = ['User_'+str(int(i)) for i in temp.index]\n",
    "    temp.columns = ['Filme_'+str(int(i)) for i in temp.columns]\n",
    "    qtd_cols = 80\n",
    "    R = temp.iloc[:, :qtd_cols]\n",
    "    l=[]\n",
    "    for i in range(1, R.shape[0]+1):\n",
    "        if R.iloc[i-1, ].isnull().sum() >= (qtd_cols - 10):\n",
    "            l.append(i)\n",
    "    R = R.drop([\"User_\"+str(r) for r in l])\n",
    "    R.index = ['User_'+str(int(i)) for i in range(R.shape[0])]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MatrixFactorization():\n",
    "    \n",
    "    def __init__(self, dataframe, K, steps, alpha, beta):\n",
    "        self.df = dataframe\n",
    "        self.K = K\n",
    "        self.steps = steps\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    def fit(self):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        R = self.df.values\n",
    "        N, M = R.shape\n",
    "        \n",
    "        #inicio aleatorio\n",
    "        P = np.random.rand(N,self.K)\n",
    "        Q = np.random.rand(self.K,M)\n",
    "        \n",
    "        lista_erro_step = []\n",
    "        \n",
    "        #loop\n",
    "        for step in range(self.steps):\n",
    "            \n",
    "            mse_total_step = 0\n",
    "            #varrendo todas as entradas da matriz R\n",
    "            for i in range(len(R)):\n",
    "                for j in range(len(R[i])):\n",
    "                    #validando se o valor associado está preenchido\n",
    "                    if R[i][j] > 0:\n",
    "\n",
    "                        #calculando o erro:\n",
    "                        eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                        mse_total_step += (eij)**2\n",
    "                        #alterando os valores\n",
    "                        for k in range(self.K):\n",
    "                            P[i][k] = P[i][k] + self.alpha * ( 2 * eij * Q[k][j] - self.beta * P[i][k])\n",
    "                            Q[k][j] = Q[k][j] + self.alpha * ( 2 * eij * P[i][k] - self.beta * Q[k][j])\n",
    "                            \n",
    "            lista_erro_step.append(mse_total_step)\n",
    "            \n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.lista_erro_step = lista_erro_step\n",
    "        t1 = time.time()\n",
    "        print(\"Fatoração concluída. Tempo aproximado:\", int((t1-t0)/60)+1, 'minuto(s).')\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.P.dot(self.Q)\n",
    "    \n",
    "    def print_MSE_steps(self):\n",
    "        plt.figure(figsize=[15,6])\n",
    "        plt.title(\"Custo total por Step\", fontsize = 16, fontweight = 'bold')\n",
    "        plt.xlabel(\"Step\", fontsize = 14, fontweight = 'bold')\n",
    "        plt.ylabel(\"Erro\", fontsize = 14, fontweight = 'bold')\n",
    "        plt.plot(range(1, 1+self.steps), self.lista_erro_step, c = 'blue', lw = 2)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "Tradicionalmente, para avaliarmos a performance de algoritmos de machine learning, fazemos a divisão dos dados em treino/teste; os dados de teste são utilizados no modelo final, apenas para validar que o mesmo não está sofrendo overfitting e está generalizando bem.\n",
    "\n",
    "No contexto dos filtros colaborativos, tal divisão dos dados não fará sentido: os métodos discutidos (de filtragem colaborativa) usam as informações de interação dos usuários com itens para \"preencher os valores faltantes\" da matriz de interação. Esse preenchimento é justamente a recomendação!\n",
    "\n",
    "<br>\n",
    "\n",
    "No entanto, podemos aplicar uma __metodologia que \"simula\" dados de treino/teste.__ \n",
    "\n",
    "Essencialmente, essa metodologia consiste de criar uma base de treino em que retiramos algumas interações dos usuários. Dessa forma, os modelos irão aprender os padrões dos dados sem terem acesso a toda informação.\n",
    "\n",
    "Nos dados de teste, usaremos essas interações retiradas em treino para avaliar os resultados.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Considere o exemplo:__\n",
    "\n",
    "Vamos carregar, novamente, o dataset que usamos ao longo do módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF():\n",
    "    dic__ = {\"User_1\":[np.nan, np.nan, np.nan, 1, 7, 2, 3, 8],\n",
    "         \"User_2\":[9,10,2,2,6,5,3,8],\n",
    "         \"User_3\":[4, 7, 9, 6,6,10,10,2],\n",
    "         \"User_4\":[np.nan, 7, 9, 5, 5, 10, 9, 1],\n",
    "         \"User_5\":[7.0,6.0,3.0,8.0,3,4.0,3.0, 2],\n",
    "         \"User_6\":[np.nan, np.nan, 9, 9,6,8,9,np.nan],\n",
    "         \"User_7\":[3,5,4,4,3,3,9,np.nan],\n",
    "         \"User_8\":[10,10,10,10,2,2,2,2],\n",
    "         \"User_9\":[9,9,np.nan,8,3,3,1,np.nan],\n",
    "         \"User_10\":[9,8,10,9,3,4,2,1],\n",
    "         \"User_11\":[4,4,3,3,9,9,8,10],\n",
    "         \"User_12\":[2,2,4,1,8,10,10,9],\n",
    "         \"User_13\":[1,4,1,3,7,10,7,8],\n",
    "         \"User_14\":[3,3,2,1,1,10, np.nan,10],\n",
    "         \"User_15\":[9,9,8,10,4,2,np.nan,1]\n",
    "        }\n",
    "    df = pd.DataFrame(dic__).T\n",
    "    df.columns = ['Filme_'+str(int(i+1)) for i in range(8)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_10</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_15</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_1       NaN      NaN      NaN      1.0      7.0      2.0      3.0   \n",
       "User_2       9.0     10.0      2.0      2.0      6.0      5.0      3.0   \n",
       "User_3       4.0      7.0      9.0      6.0      6.0     10.0     10.0   \n",
       "User_4       NaN      7.0      9.0      5.0      5.0     10.0      9.0   \n",
       "User_5       7.0      6.0      3.0      8.0      3.0      4.0      3.0   \n",
       "User_6       NaN      NaN      9.0      9.0      6.0      8.0      9.0   \n",
       "User_7       3.0      5.0      4.0      4.0      3.0      3.0      9.0   \n",
       "User_8      10.0     10.0     10.0     10.0      2.0      2.0      2.0   \n",
       "User_9       9.0      9.0      NaN      8.0      3.0      3.0      1.0   \n",
       "User_10      9.0      8.0     10.0      9.0      3.0      4.0      2.0   \n",
       "User_11      4.0      4.0      3.0      3.0      9.0      9.0      8.0   \n",
       "User_12      2.0      2.0      4.0      1.0      8.0     10.0     10.0   \n",
       "User_13      1.0      4.0      1.0      3.0      7.0     10.0      7.0   \n",
       "User_14      3.0      3.0      2.0      1.0      1.0     10.0      NaN   \n",
       "User_15      9.0      9.0      8.0     10.0      4.0      2.0      NaN   \n",
       "\n",
       "         Filme_8  \n",
       "User_1       8.0  \n",
       "User_2       8.0  \n",
       "User_3       2.0  \n",
       "User_4       1.0  \n",
       "User_5       2.0  \n",
       "User_6       NaN  \n",
       "User_7       NaN  \n",
       "User_8       2.0  \n",
       "User_9       NaN  \n",
       "User_10      1.0  \n",
       "User_11     10.0  \n",
       "User_12      9.0  \n",
       "User_13      8.0  \n",
       "User_14     10.0  \n",
       "User_15      1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = getDF()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Abaixo, criamos o array \"ratings\", que consiste de nossa matriz de interação usuário/item. No entanto, fizemos um completamento com \"0\" nos dados faltantes. Dessa forma, o rating = 0 significa que o usuário não avaliou o filme em questão.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  7.,  2.,  3.,  8.],\n",
       "       [ 9., 10.,  2.,  2.,  6.,  5.,  3.,  8.],\n",
       "       [ 4.,  7.,  9.,  6.,  6., 10., 10.,  2.],\n",
       "       [ 0.,  7.,  9.,  5.,  5., 10.,  9.,  1.],\n",
       "       [ 7.,  6.,  3.,  8.,  3.,  4.,  3.,  2.],\n",
       "       [ 0.,  0.,  9.,  9.,  6.,  8.,  9.,  0.],\n",
       "       [ 3.,  5.,  4.,  4.,  3.,  3.,  9.,  0.],\n",
       "       [10., 10., 10., 10.,  2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  0.,  8.,  3.,  3.,  1.,  0.],\n",
       "       [ 9.,  8., 10.,  9.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  9.,  9.,  8., 10.],\n",
       "       [ 2.,  2.,  4.,  1.,  8., 10., 10.,  9.],\n",
       "       [ 1.,  4.,  1.,  3.,  7., 10.,  7.,  8.],\n",
       "       [ 3.,  3.,  2.,  1.,  1., 10.,  0., 10.],\n",
       "       [ 9.,  9.,  8., 10.,  4.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = df.fillna(0).values\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Na sequência, apresentamos a função que faz a divisão dos dados em treino e teste.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings, qtd):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=qtd, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, qtd = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Vamos comparar os dados de treino e teste com os dados originais:__\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  7.,  2.,  3.,  8.],\n",
       "       [ 9., 10.,  2.,  2.,  6.,  5.,  3.,  8.],\n",
       "       [ 4.,  7.,  9.,  6.,  6., 10., 10.,  2.],\n",
       "       [ 0.,  7.,  9.,  5.,  5., 10.,  9.,  1.],\n",
       "       [ 7.,  6.,  3.,  8.,  3.,  4.,  3.,  2.],\n",
       "       [ 0.,  0.,  9.,  9.,  6.,  8.,  9.,  0.],\n",
       "       [ 3.,  5.,  4.,  4.,  3.,  3.,  9.,  0.],\n",
       "       [10., 10., 10., 10.,  2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  0.,  8.,  3.,  3.,  1.,  0.],\n",
       "       [ 9.,  8., 10.,  9.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  9.,  9.,  8., 10.],\n",
       "       [ 2.,  2.,  4.,  1.,  8., 10., 10.,  9.],\n",
       "       [ 1.,  4.,  1.,  3.,  7., 10.,  7.,  8.],\n",
       "       [ 3.,  3.,  2.,  1.,  1., 10.,  0., 10.],\n",
       "       [ 9.,  9.,  8., 10.,  4.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matriz de interação - original;\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  7.,  0.,  0.,  8.],\n",
       "       [ 9., 10.,  2.,  2.,  6.,  0.,  3.,  0.],\n",
       "       [ 4.,  7.,  9.,  6.,  0., 10., 10.,  0.],\n",
       "       [ 0.,  7.,  0.,  5.,  0., 10.,  9.,  1.],\n",
       "       [ 7.,  6.,  0.,  8.,  0.,  4.,  3.,  2.],\n",
       "       [ 0.,  0.,  0.,  0.,  6.,  8.,  9.,  0.],\n",
       "       [ 0.,  5.,  4.,  4.,  3.,  3.,  0.,  0.],\n",
       "       [10., 10., 10.,  0.,  2.,  2.,  2.,  0.],\n",
       "       [ 0.,  9.,  0.,  8.,  3.,  3.,  0.,  0.],\n",
       "       [ 0.,  0., 10.,  9.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  9.,  9.,  0.,  0.],\n",
       "       [ 0.,  2.,  4.,  1.,  8., 10., 10.,  0.],\n",
       "       [ 1.,  4.,  1.,  3.,  0., 10.,  7.,  0.],\n",
       "       [ 3.,  0.,  2.,  1.,  0., 10.,  0., 10.],\n",
       "       [ 9.,  9.,  0., 10.,  4.,  2.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dados de treino;\n",
    "#observe que, para cada usuário (ou seja, para cada linha) 3 notas foram retiradas!! \n",
    "#ou seja, foram substituida por 0.\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  2.,  3.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  5.,  0.,  8.],\n",
       "       [ 0.,  0.,  0.,  0.,  6.,  0.,  0.,  2.],\n",
       "       [ 0.,  0.,  9.,  0.,  5.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  3.,  0.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  9.,  9.,  0.,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0.,  0.,  0.,  0.,  9.,  0.],\n",
       "       [ 0.,  0.,  0., 10.,  0.,  0.,  0.,  2.],\n",
       "       [ 9.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 9.,  8.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  8., 10.],\n",
       "       [ 2.,  0.,  0.,  0.,  0.,  0.,  0.,  9.],\n",
       "       [ 0.,  0.,  0.,  0.,  7.,  0.,  0.,  8.],\n",
       "       [ 0.,  3.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  8.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dados de teste;\n",
    "#observe que exatamente as notas que foram retiradas de treino são colocadas nessa matriz de teste!!\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Na prática, usaremos os dados de treino para treinar e escolher os modelos.\n",
    "\n",
    "Neste caso, podemos, inclusive, fazer a divisão em treino/validação/teste:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, qtd = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.],\n",
       "       [ 0., 10.,  2.,  0.,  6.,  0.,  3.,  0.],\n",
       "       [ 4.,  7.,  0.,  6.,  0.,  0., 10.,  0.],\n",
       "       [ 0.,  7.,  0.,  0.,  0.,  0.,  9.,  1.],\n",
       "       [ 7.,  0.,  0.,  8.,  0.,  4.,  3.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.],\n",
       "       [ 0.,  5.,  0.,  4.,  3.,  0.,  0.,  0.],\n",
       "       [ 0., 10., 10.,  0.,  2.,  2.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  8.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 10.,  0.,  3.,  0.,  2.,  1.],\n",
       "       [ 0.,  4.,  3.,  0.,  9.,  9.,  0.,  0.],\n",
       "       [ 0.,  2.,  4.,  1.,  8.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.,  0., 10.,  7.,  0.],\n",
       "       [ 3.,  0.,  2.,  0.,  0.,  0.,  0., 10.],\n",
       "       [ 9.,  0.,  0.,  0.,  4.,  2.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  8.],\n",
       "       [ 9.,  0.,  0.,  2.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  9.,  0.,  0., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  5.,  0., 10.,  0.,  0.],\n",
       "       [ 0.,  6.,  0.,  0.,  0.,  0.,  0.,  2.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  8.,  9.,  0.],\n",
       "       [ 0.,  0.,  4.,  0.,  0.,  3.,  0.,  0.],\n",
       "       [10.,  0.,  0.,  0.,  0.,  0.,  2.,  0.],\n",
       "       [ 0.,  9.,  0.,  0.,  0.,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  9.,  0.,  4.,  0.,  0.],\n",
       "       [ 4.,  0.,  0.,  3.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0., 10., 10.,  0.],\n",
       "       [ 0.,  4.,  0.,  3.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0., 10.,  0.,  0.],\n",
       "       [ 0.,  9.,  0., 10.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  2.,  3.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  5.,  0.,  8.],\n",
       "       [ 0.,  0.,  0.,  0.,  6.,  0.,  0.,  2.],\n",
       "       [ 0.,  0.,  9.,  0.,  5.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  3.,  0.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  9.,  9.,  0.,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0.,  0.,  0.,  0.,  9.,  0.],\n",
       "       [ 0.,  0.,  0., 10.,  0.,  0.,  0.,  2.],\n",
       "       [ 9.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 9.,  8.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  8., 10.],\n",
       "       [ 2.,  0.,  0.,  0.,  0.,  0.,  0.,  9.],\n",
       "       [ 0.,  0.,  0.,  0.,  7.,  0.,  0.,  8.],\n",
       "       [ 0.,  3.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  8.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Observe que, se \"juntamos\" os dados das 3 tabelas acima, retornamos com os dados originais:\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  7.,  2.,  3.,  8.],\n",
       "       [ 9., 10.,  2.,  2.,  6.,  5.,  3.,  8.],\n",
       "       [ 4.,  7.,  9.,  6.,  6., 10., 10.,  2.],\n",
       "       [ 0.,  7.,  9.,  5.,  5., 10.,  9.,  1.],\n",
       "       [ 7.,  6.,  3.,  8.,  3.,  4.,  3.,  2.],\n",
       "       [ 0.,  0.,  9.,  9.,  6.,  8.,  9.,  0.],\n",
       "       [ 3.,  5.,  4.,  4.,  3.,  3.,  9.,  0.],\n",
       "       [10., 10., 10., 10.,  2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  0.,  8.,  3.,  3.,  1.,  0.],\n",
       "       [ 9.,  8., 10.,  9.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  9.,  9.,  8., 10.],\n",
       "       [ 2.,  2.,  4.,  1.,  8., 10., 10.,  9.],\n",
       "       [ 1.,  4.,  1.,  3.,  7., 10.,  7.,  8.],\n",
       "       [ 3.,  3.,  2.,  1.,  1., 10.,  0., 10.],\n",
       "       [ 9.,  9.,  8., 10.,  4.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train + val + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train + val + test) == ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Ou seja, com a metodologia acima, temos uma \"divisão\" dos dados em treino/validação/teste!\n",
    "\n",
    "\n",
    "Desta forma, podemos usar a metologia padrão de avaliação dos modelos:\n",
    "    \n",
    "    - Fitamos os modelos nos dados de treino;\n",
    "    \n",
    "    - Avaliamos os modelos nos dados de validação;\n",
    "    \n",
    "    - Escolhemos o modelo final, a partir dos resultados de validação;\n",
    "    \n",
    "    - Avaliamos o modelo final nos dados de teste.\n",
    "    \n",
    "    \n",
    "<br>\n",
    "\n",
    "\n",
    "__Ponto de atenção:__\n",
    "\n",
    "Ao calcularmos as métricas de performance, apenas os valores não nulos dos dados de validação/teste devem ser usados.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Vejamos um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fat = MatrixFactorization(dataframe = pd.DataFrame(train, columns = df.columns, index = df.index), \n",
    "                          K = 5, steps = 5000, alpha = 0.0001, beta = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 1 minuto(s).\n"
     ]
    }
   ],
   "source": [
    "fat.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>4.20</td>\n",
       "      <td>6.34</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5.01</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.95</td>\n",
       "      <td>5.81</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>6.05</td>\n",
       "      <td>9.51</td>\n",
       "      <td>2.31</td>\n",
       "      <td>8.15</td>\n",
       "      <td>5.75</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.22</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>3.87</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.05</td>\n",
       "      <td>8.23</td>\n",
       "      <td>11.29</td>\n",
       "      <td>9.45</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>4.35</td>\n",
       "      <td>6.85</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.86</td>\n",
       "      <td>9.85</td>\n",
       "      <td>8.72</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_5</th>\n",
       "      <td>6.95</td>\n",
       "      <td>9.42</td>\n",
       "      <td>5.20</td>\n",
       "      <td>7.69</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.06</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_6</th>\n",
       "      <td>3.76</td>\n",
       "      <td>5.65</td>\n",
       "      <td>3.71</td>\n",
       "      <td>4.42</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.64</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_7</th>\n",
       "      <td>3.63</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_8</th>\n",
       "      <td>8.64</td>\n",
       "      <td>9.74</td>\n",
       "      <td>9.69</td>\n",
       "      <td>7.28</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_9</th>\n",
       "      <td>6.05</td>\n",
       "      <td>8.86</td>\n",
       "      <td>2.41</td>\n",
       "      <td>7.75</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.13</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_10</th>\n",
       "      <td>7.32</td>\n",
       "      <td>8.03</td>\n",
       "      <td>9.60</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_11</th>\n",
       "      <td>2.09</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.99</td>\n",
       "      <td>8.61</td>\n",
       "      <td>8.97</td>\n",
       "      <td>5.85</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_12</th>\n",
       "      <td>1.21</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.03</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7.07</td>\n",
       "      <td>3.71</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.31</td>\n",
       "      <td>7.08</td>\n",
       "      <td>9.43</td>\n",
       "      <td>7.27</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_14</th>\n",
       "      <td>3.16</td>\n",
       "      <td>5.62</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.43</td>\n",
       "      <td>8.25</td>\n",
       "      <td>6.38</td>\n",
       "      <td>3.82</td>\n",
       "      <td>9.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_15</th>\n",
       "      <td>8.62</td>\n",
       "      <td>10.83</td>\n",
       "      <td>7.35</td>\n",
       "      <td>8.53</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_1      4.20     6.34     4.25     5.01     6.88     7.95     5.81   \n",
       "User_2      6.05     9.51     2.31     8.15     5.75     4.31     3.22   \n",
       "User_3      3.87     6.99     1.97     6.05     8.23    11.29     9.45   \n",
       "User_4      4.35     6.85     3.25     5.89     5.86     9.85     8.72   \n",
       "User_5      6.95     9.42     5.20     7.69     4.31     3.92     3.06   \n",
       "User_6      3.76     5.65     3.71     4.42     5.91     5.64     3.65   \n",
       "User_7      3.63     4.94     3.23     3.93     2.96     2.76     1.91   \n",
       "User_8      8.64     9.74     9.69     7.28     2.28     1.87     1.16   \n",
       "User_9      6.05     8.86     2.41     7.75     3.05     3.94     4.13   \n",
       "User_10     7.32     8.03     9.60     5.75     3.00     3.25     1.98   \n",
       "User_11     2.09     4.04     2.96     2.99     8.61     8.97     5.85   \n",
       "User_12     1.21     2.11     3.88     1.03     7.60     7.07     3.71   \n",
       "User_13     1.00     2.79     1.09     2.31     7.08     9.43     7.27   \n",
       "User_14     3.16     5.62     1.85     4.43     8.25     6.38     3.82   \n",
       "User_15     8.62    10.83     7.35     8.53     3.82     2.15     1.33   \n",
       "\n",
       "         Filme_8  \n",
       "User_1      3.84  \n",
       "User_2      6.80  \n",
       "User_3      4.81  \n",
       "User_4      1.09  \n",
       "User_5      4.36  \n",
       "User_6      3.99  \n",
       "User_7      2.22  \n",
       "User_8      1.95  \n",
       "User_9      3.45  \n",
       "User_10     1.00  \n",
       "User_11     5.26  \n",
       "User_12     4.31  \n",
       "User_13     3.21  \n",
       "User_14     9.68  \n",
       "User_15     5.62  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição usando apenas os dados de treino!!\n",
    "\n",
    "pd.DataFrame(fat.predict(), columns = df.columns, index = df.index).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Veja que a matriz resultante __não é esparsa!__\n",
    "\n",
    "Dessa forma, como sabemos, podemos utilizá-la para as recomendações.\n",
    "\n",
    "Como __nosso objetivo no exercício é avaliar performance__, podemos __comparar__ os resultados dessa matriz resultante com os valores dos dados de validação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_1       0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "User_2       9.0      0.0      0.0      2.0      0.0      0.0      0.0   \n",
       "User_3       0.0      0.0      9.0      0.0      0.0     10.0      0.0   \n",
       "User_4       0.0      0.0      0.0      5.0      0.0     10.0      0.0   \n",
       "User_5       0.0      6.0      0.0      0.0      0.0      0.0      0.0   \n",
       "User_6       0.0      0.0      0.0      0.0      0.0      8.0      9.0   \n",
       "User_7       0.0      0.0      4.0      0.0      0.0      3.0      0.0   \n",
       "User_8      10.0      0.0      0.0      0.0      0.0      0.0      2.0   \n",
       "User_9       0.0      9.0      0.0      0.0      0.0      3.0      0.0   \n",
       "User_10      0.0      0.0      0.0      9.0      0.0      4.0      0.0   \n",
       "User_11      4.0      0.0      0.0      3.0      0.0      0.0      0.0   \n",
       "User_12      0.0      0.0      0.0      0.0      0.0     10.0     10.0   \n",
       "User_13      0.0      4.0      0.0      3.0      0.0      0.0      0.0   \n",
       "User_14      0.0      0.0      0.0      1.0      0.0     10.0      0.0   \n",
       "User_15      0.0      9.0      0.0     10.0      0.0      0.0      0.0   \n",
       "\n",
       "         Filme_8  \n",
       "User_1       8.0  \n",
       "User_2       0.0  \n",
       "User_3       0.0  \n",
       "User_4       0.0  \n",
       "User_5       2.0  \n",
       "User_6       0.0  \n",
       "User_7       0.0  \n",
       "User_8       0.0  \n",
       "User_9       0.0  \n",
       "User_10      0.0  \n",
       "User_11      0.0  \n",
       "User_12      0.0  \n",
       "User_13      0.0  \n",
       "User_14      0.0  \n",
       "User_15      0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val, columns = df.columns, index = df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercício:\n",
    "\n",
    "Carregue o conjunto de dados a partir da função getData() e utilize o modelo de fatoração matricial.\n",
    "\n",
    "Faça uma divisão dos dados em treino/validação/teste de acordo com a metodologia acima discutida (Utilize qtd = 2, ou seja, 2 interações por usuário serão retiradas na divisão dos dados). \n",
    "\n",
    "Testando vários conjuntos de parâmetros - isto é, um análogo ao Grid Search de modelos - encontre a melhor fatoração matricial para realizarmos recomendações neste dataset.\n",
    "\n",
    "Obs.: esse grid search acima pode ser feito manualmente, implementado num loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "      <th>Filme_9</th>\n",
       "      <th>Filme_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Filme_71</th>\n",
       "      <th>Filme_72</th>\n",
       "      <th>Filme_73</th>\n",
       "      <th>Filme_74</th>\n",
       "      <th>Filme_75</th>\n",
       "      <th>Filme_76</th>\n",
       "      <th>Filme_77</th>\n",
       "      <th>Filme_78</th>\n",
       "      <th>Filme_79</th>\n",
       "      <th>Filme_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_362</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_363</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_364</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_0        5.0      3.0      4.0      3.0      3.0      5.0      4.0   \n",
       "User_1        4.0      3.0      NaN      NaN      NaN      NaN      NaN   \n",
       "User_2        4.0      NaN      NaN      NaN      NaN      NaN      2.0   \n",
       "User_3        NaN      NaN      NaN      5.0      NaN      NaN      5.0   \n",
       "User_4        4.0      NaN      NaN      4.0      NaN      NaN      4.0   \n",
       "...           ...      ...      ...      ...      ...      ...      ...   \n",
       "User_362      3.0      NaN      NaN      3.0      NaN      NaN      4.0   \n",
       "User_363      2.0      4.0      NaN      5.0      NaN      NaN      NaN   \n",
       "User_364      4.0      NaN      4.0      NaN      NaN      5.0      4.0   \n",
       "User_365      NaN      NaN      NaN      2.0      NaN      NaN      4.0   \n",
       "User_366      NaN      5.0      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "          Filme_8  Filme_9  Filme_10  ...  Filme_71  Filme_72  Filme_73  \\\n",
       "User_0        1.0      5.0       3.0  ...       3.0       4.0       3.0   \n",
       "User_1        NaN      NaN       NaN  ...       NaN       NaN       NaN   \n",
       "User_2        4.0      4.0       NaN  ...       4.0       NaN       NaN   \n",
       "User_3        5.0      5.0       4.0  ...       5.0       5.0       3.0   \n",
       "User_4        NaN      4.0       NaN  ...       NaN       NaN       NaN   \n",
       "...           ...      ...       ...  ...       ...       ...       ...   \n",
       "User_362      NaN      3.0       NaN  ...       NaN       3.0       4.0   \n",
       "User_363      NaN      NaN       NaN  ...       NaN       3.0       NaN   \n",
       "User_364      NaN      4.0       NaN  ...       NaN       NaN       NaN   \n",
       "User_365      5.0      3.0       NaN  ...       NaN       NaN       NaN   \n",
       "User_366      NaN      3.0       NaN  ...       NaN       2.0       3.0   \n",
       "\n",
       "          Filme_74  Filme_75  Filme_76  Filme_77  Filme_78  Filme_79  Filme_80  \n",
       "User_0         1.0       4.0       4.0       4.0       1.0       4.0       4.0  \n",
       "User_1         NaN       NaN       NaN       NaN       NaN       3.0       2.0  \n",
       "User_2         NaN       NaN       NaN       NaN       NaN       3.0       NaN  \n",
       "User_3         NaN       NaN       NaN       5.0       3.0       4.0       4.0  \n",
       "User_4         NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "...            ...       ...       ...       ...       ...       ...       ...  \n",
       "User_362       NaN       NaN       NaN       NaN       NaN       3.0       2.0  \n",
       "User_363       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "User_364       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "User_365       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "User_366       NaN       NaN       4.0       NaN       NaN       5.0       2.0  \n",
       "\n",
       "[367 rows x 80 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = getData()\n",
    "print(R.shape)\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeiro passo: trocar todos os dados faltantes por 0 e tranformar nosso dataset num array, porém vamos fazer uma rápida análise de quantos dados faltantes temos no total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20471"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulo = R.isnull().sum().sum()\n",
    "\n",
    "nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697241144414169"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# em termos de porcentagem:\n",
    "\n",
    "a = R.isnull().sum().sum()/(R.shape[0]*R.shape[1])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quase 70% dos dados são nulos, precisamos de um baixo erro para preencher esses dados da melhor maneira possível. Agora sim, vamos trocar os dados faltantes por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_ex = R.fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 1., 4., 4.],\n",
       "       [4., 3., 0., ..., 0., 3., 2.],\n",
       "       [4., 0., 0., ..., 0., 3., 0.],\n",
       "       ...,\n",
       "       [4., 0., 4., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 5., 2.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segundo passo: Dividir os dados em dados de treino, validação e teste usando a função dada no exercício."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino, teste = train_test_split(ratings_ex, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 1., 4., 4.],\n",
       "       [4., 3., 0., ..., 0., 3., 2.],\n",
       "       [4., 0., 0., ..., 0., 3., 0.],\n",
       "       ...,\n",
       "       [4., 0., 4., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 5., 2.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino, valid = train_test_split(treino, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 1., 4., 4.],\n",
       "       [4., 3., 0., ..., 0., 3., 2.],\n",
       "       [4., 0., 0., ..., 0., 3., 0.],\n",
       "       ...,\n",
       "       [4., 0., 4., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 5., 2.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de criar nosso GridSeach, vamos fazer uma fatoração nos nosso dados com parâmetros fixados, entre eles, 500 passos, depois disso, analisaremos o gráfico de erro, e assim poderemos ter uma noção intuitiva da quantidade máxima de passos que devemos escolher para fazer o GridSeach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fato = MatrixFactorization(dataframe = pd.DataFrame(treino, columns = R.columns, index = R.index), \n",
    "                          K = 10, steps = 200, alpha = 0.0002, beta = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n"
     ]
    }
   ],
   "source": [
    "fato.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fato.print_MSE_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos uma noção da quantidade de passos que precisaremos (entre 150 e 300), vamos criar uma função parecida com o MSE, onde vai nos retornar o erro quando compararmos nossos dados de treino, com os de validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_error(y_pred,y_true):\n",
    "    \n",
    "    R = y_true\n",
    "    Rp = y_pred\n",
    "    \n",
    "    lista_erro = []\n",
    "    \n",
    "    mse_total_step = 0\n",
    "\n",
    "    for i in range(len(R)):\n",
    "        for j in range(len(R[i])):\n",
    "                   \n",
    "            if R[i][j] > 0:\n",
    "                eij = R[i][j] - Rp[i][j]\n",
    "                    \n",
    "                mse_total_step += (eij)**2\n",
    "                        \n",
    "                        \n",
    "    lista_erro.append(mse_total_step)\n",
    "    \n",
    "    return lista_erro[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos fazer nosso GridSeach por partes, inicialmente fixaremos:\n",
    "\n",
    "__Alpha = 0.0001__\n",
    "\n",
    "__Beta = 0.1__\n",
    "\n",
    "__Número de Passos = 200__\n",
    "\n",
    "E iremos variar a dimensão do espaço latente K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 1 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.001, beta = 0.1, Steps = 200, K =   3\n",
      "Erro em dados de treino:  4817.589520296703 \n",
      "Erro em dados de Validação:  585.6997971126938 \n",
      "Erro em dados de teste:  699.238672530255 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 1 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.001, beta = 0.1, Steps = 200, K =   5\n",
      "Erro em dados de treino:  4173.664869073066 \n",
      "Erro em dados de Validação:  624.3441194051841 \n",
      "Erro em dados de teste:  735.8610042119882 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.001, beta = 0.1, Steps = 200, K =   10\n",
      "Erro em dados de treino:  3061.7009805091134 \n",
      "Erro em dados de Validação:  663.595914890245 \n",
      "Erro em dados de teste:  751.5796188878983 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 6 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.001, beta = 0.1, Steps = 200, K =   40\n",
      "Erro em dados de treino:  1130.6351190555147 \n",
      "Erro em dados de Validação:  658.5688181907437 \n",
      "Erro em dados de teste:  772.2664793146367 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 9 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.001, beta = 0.1, Steps = 200, K =   60\n",
      "Erro em dados de treino:  823.1082215204145 \n",
      "Erro em dados de Validação:  664.8439896942859 \n",
      "Erro em dados de teste:  782.3349435836781 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [3,5,10,40,60]:\n",
    "                \n",
    "    fato = MatrixFactorization(dataframe = pd.DataFrame(treino, columns = R.columns, index = R.index), \n",
    "                          K = k, steps = 200, alpha = 0.001, beta = 0.1)\n",
    "                \n",
    "    fato.fit()\n",
    "    \n",
    "    mse = mse_error(y_pred = fato.predict(), y_true = valid)\n",
    "    mse1 = mse_error(y_pred = fato.predict(), y_true = teste)\n",
    "                \n",
    "    print('\\nParâmetros utilidados: alpha = 0.001, beta = 0.1, Steps = 200, K =  ', k)\n",
    "    print('Erro em dados de treino: ', fato.lista_erro_step[-1], '\\nErro em dados de Validação: ', mse, \n",
    "          '\\nErro em dados de teste: ', mse1, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira observação que devemos fazer é que a diferença dos erros do dado de treino para validação e teste se da pelo fato de que nos dados de validação e de teste, somente duas das colunas são não nulas, e consequêntemente ao fazer o somatório da nossa função mse_error, esse número vai ser menor do que o erro encontrado pela fatoração nos dados de treino.\n",
    "\n",
    "Outra coisa que devemos obserar é que minimizar o erro nos dados de treino é bom, porém os dados 'desconhecidos' são os dados de validação e de teste, portanto, não adianta ter um erro muito baixo no dados de treino, se esse erro aumenta nos dados de validação e de teste, pois assim, temos uma chance mais alta de overfiting.\n",
    "\n",
    "Tendo em vista essas observações, vamos escolhar K = 10 para ser a dimensão do nosso espaço latente, pois nele temos um baixo erro nos dados de treino e erros mais baixos nos dados de validação e teste comparados com K = 40 e 60.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora fixando k = 10, vamos fazer a variação no alpha e ver os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha =  0.001 beta = 0.1, Steps = 200, K =  10\n",
      "Erro em dados de treino:  3176.0052167809213 \n",
      "Erro em dados de Validação:  624.3835056932573 \n",
      "Erro em dados de teste:  763.5105183001924 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha =  0.002 beta = 0.1, Steps = 200, K =  10\n",
      "Erro em dados de treino:  2445.5642565119197 \n",
      "Erro em dados de Validação:  715.5716045826306 \n",
      "Erro em dados de teste:  782.7351340522534 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha =  0.003 beta = 0.1, Steps = 200, K =  10\n",
      "Erro em dados de treino:  2261.3706782762515 \n",
      "Erro em dados de Validação:  739.8828247225316 \n",
      "Erro em dados de teste:  770.192385603037 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha =  0.004 beta = 0.1, Steps = 200, K =  10\n",
      "Erro em dados de treino:  2166.876886278131 \n",
      "Erro em dados de Validação:  791.1198056137805 \n",
      "Erro em dados de teste:  801.1843645718733 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha =  0.005 beta = 0.1, Steps = 200, K =  10\n",
      "Erro em dados de treino:  2195.292305738902 \n",
      "Erro em dados de Validação:  732.9566144742489 \n",
      "Erro em dados de teste:  813.9215968178577 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha =  0.006 beta = 0.1, Steps = 200, K =  10\n",
      "Erro em dados de treino:  2199.0175805227823 \n",
      "Erro em dados de Validação:  831.3077808877189 \n",
      "Erro em dados de teste:  857.2797885216411 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.arange(0.001,0.007, 0.001):\n",
    "                \n",
    "    fato = MatrixFactorization(dataframe = pd.DataFrame(treino, columns = R.columns, index = R.index), \n",
    "                          K = 10, steps = 200, alpha = alpha, beta = 0.1)\n",
    "                \n",
    "    fato.fit()\n",
    "    \n",
    "    mse = mse_error(y_pred = fato.predict(), y_true = valid)\n",
    "    mse1 = mse_error(y_pred = fato.predict(), y_true = teste)\n",
    "                \n",
    "    print('\\nParâmetros utilidados: alpha = ', alpha, 'beta = 0.1, Steps = 200, K =  10')\n",
    "    print('Erro em dados de treino: ', fato.lista_erro_step[-1], '\\nErro em dados de Validação: ', mse, \n",
    "          '\\nErro em dados de teste: ', mse1, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que de 0.003 para cima, o erro nos dados de treino pouco mudou, enquanto nos dados de  validação e teste, aumentaram.\n",
    "\n",
    "Entre 0.001 e 0.002, pela diferença entre os valores, afim de evitar algum possível overfiting, vamos escolher alpha = 0.002.\n",
    "\n",
    "Agora já temos fixados:\n",
    "\n",
    "__K = 10__\n",
    "\n",
    "__Alpha = 0.001__\n",
    "\n",
    "Vamos então encontrar possíveis valores para Beta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta =  0.1 Steps = 200, K =  10\n",
      "Erro em dados de treino:  2456.0493110925017 \n",
      "Erro em dados de Validação:  670.7596293375715 \n",
      "Erro em dados de teste:  767.9555217045585 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta =  0.2 Steps = 200, K =  10\n",
      "Erro em dados de treino:  3089.8402342312083 \n",
      "Erro em dados de Validação:  623.6663162378925 \n",
      "Erro em dados de teste:  702.1543214652692 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta =  0.30000000000000004 Steps = 200, K =  10\n",
      "Erro em dados de treino:  4075.882486460002 \n",
      "Erro em dados de Validação:  574.1422170500161 \n",
      "Erro em dados de teste:  679.9905284512436 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 3 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta =  0.4 Steps = 200, K =  10\n",
      "Erro em dados de treino:  5024.664150580431 \n",
      "Erro em dados de Validação:  580.0541419988449 \n",
      "Erro em dados de teste:  686.2515779305235 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 3 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta =  0.5 Steps = 200, K =  10\n",
      "Erro em dados de treino:  5720.828388959029 \n",
      "Erro em dados de Validação:  599.6202499791848 \n",
      "Erro em dados de teste:  705.0150341279546 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta =  0.6 Steps = 200, K =  10\n",
      "Erro em dados de treino:  6362.028560762174 \n",
      "Erro em dados de Validação:  633.3643721482003 \n",
      "Erro em dados de teste:  735.8539338590704 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for beta in np.arange(0.1,0.7, 0.1):\n",
    "                \n",
    "    fato = MatrixFactorization(dataframe = pd.DataFrame(treino, columns = R.columns, index = R.index), \n",
    "                          K = 10, steps = 200, alpha = 0.002, beta = beta)\n",
    "                \n",
    "    fato.fit()\n",
    "    \n",
    "    mse = mse_error(y_pred = fato.predict(), y_true = valid)\n",
    "    mse1 = mse_error(y_pred = fato.predict(), y_true = teste)\n",
    "                \n",
    "    print('\\nParâmetros utilidados: alpha = 0.002', 'beta = ' , beta, 'Steps = 200, K =  10')\n",
    "    print('Erro em dados de treino: ', fato.lista_erro_step[-1], '\\nErro em dados de Validação: ', mse, \n",
    "          '\\nErro em dados de teste: ', mse1, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos algo bem intessante aqui, até beta = 0.3, apesar do erro em dados de treino ter aumentado, o erro nos dados de validação e teste, abaixaram, vamos escolher um meio termo para nossa regularização, beta = 0.2\n",
    "\n",
    "Para finalizar nosso GridSearch, vamos fazer uma variação no número de passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 1 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta = 0.2, Steps = 50  K =  10\n",
      "Erro em dados de treino:  4986.42889663429 \n",
      "Erro em dados de Validação:  603.8952714463453 \n",
      "Erro em dados de teste:  712.5550044957585 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 1 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta = 0.2, Steps = 100  K =  10\n",
      "Erro em dados de treino:  3845.5549759178625 \n",
      "Erro em dados de Validação:  618.9722635083359 \n",
      "Erro em dados de teste:  685.6835481766689 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 2 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta = 0.2, Steps = 150  K =  10\n",
      "Erro em dados de treino:  3359.4517630588907 \n",
      "Erro em dados de Validação:  590.2490967737846 \n",
      "Erro em dados de teste:  748.5543374339212 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 3 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta = 0.2, Steps = 200  K =  10\n",
      "Erro em dados de treino:  3060.541234368548 \n",
      "Erro em dados de Validação:  621.3233110892327 \n",
      "Erro em dados de teste:  717.0550751754396 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 3 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta = 0.2, Steps = 250  K =  10\n",
      "Erro em dados de treino:  2929.57439842971 \n",
      "Erro em dados de Validação:  607.6334284267526 \n",
      "Erro em dados de teste:  705.4089029809819 \n",
      "\n",
      "Fatoração concluída. Tempo aproximado: 3 minuto(s).\n",
      "\n",
      "Parâmetros utilidados: alpha = 0.002 beta = 0.2, Steps = 300  K =  10\n",
      "Erro em dados de treino:  2874.1945141510805 \n",
      "Erro em dados de Validação:  607.7244269243027 \n",
      "Erro em dados de teste:  713.2207332516715 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for steps in np.arange(50,350,50):\n",
    "                \n",
    "    fato = MatrixFactorization(dataframe = pd.DataFrame(treino, columns = R.columns, index = R.index), \n",
    "                          K = 10, steps = steps, alpha = 0.002, beta = 0.2)\n",
    "                \n",
    "    fato.fit()\n",
    "    \n",
    "    mse = mse_error(y_pred = fato.predict(), y_true = valid)\n",
    "    mse1 = mse_error(y_pred = fato.predict(), y_true = teste)\n",
    "                \n",
    "    print('\\nParâmetros utilidados: alpha = 0.002', 'beta = 0.2, Steps =', steps, ' K =  10')\n",
    "    print('Erro em dados de treino: ', fato.lista_erro_step[-1], '\\nErro em dados de Validação: ', mse, \n",
    "          '\\nErro em dados de teste: ', mse1, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizamos então escolhendo nosso último parâmetro, número de passos = 250.\n",
    "\n",
    "Mais uma observação que podemos fazer é que poderiamos ter colocado todas essas variações de parâmetros em um único código, iria demorar mais tempo e teriamos mais combinações para analisar, mas fazendo assim passo a passo, conseguimos entender o que ta acontecendo e conseguimos bons resultados.\n",
    "\n",
    "Vamos finalizar então criando nosso objeto com os parâmetros escolhidos para depois fitar e aplicar no nosso dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 3 minuto(s).\n"
     ]
    }
   ],
   "source": [
    "fato1 = MatrixFactorization(dataframe = pd.DataFrame(ratings_ex, columns = R.columns, index = R.index), \n",
    "                          K = 10, steps = 250, alpha = 0.002, beta = 0.2)\n",
    "                \n",
    "\n",
    "fato1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3814.7880196879023"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fato1.lista_erro_step[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fato1.print_MSE_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizamos aqui com um ótimo resultado, se dividirmos o erro pela quantidade de registros não nulos nos obtemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42915828773629233"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_erro = fato1.lista_erro_step[-1]/(R.shape[0]*R.shape[1]-nulo)\n",
    "\n",
    "media_erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, o quadrado da diferença dos valores originais para os preditos pela matriz de fatoração é em média de 0.43, um número muito baixo.\n",
    "\n",
    "Para conferir o quão próximo chegamos, podemos comparar uma linha das duas tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "      <th>Filme_9</th>\n",
       "      <th>Filme_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_0</th>\n",
       "      <td>3.633915</td>\n",
       "      <td>2.956317</td>\n",
       "      <td>3.542881</td>\n",
       "      <td>3.312958</td>\n",
       "      <td>3.039617</td>\n",
       "      <td>3.817698</td>\n",
       "      <td>3.707119</td>\n",
       "      <td>3.480896</td>\n",
       "      <td>4.242296</td>\n",
       "      <td>3.758695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filme_1   Filme_2   Filme_3   Filme_4   Filme_5   Filme_6   Filme_7  \\\n",
       "User_0  3.633915  2.956317  3.542881  3.312958  3.039617  3.817698  3.707119   \n",
       "\n",
       "         Filme_8   Filme_9  Filme_10  \n",
       "User_0  3.480896  4.242296  3.758695  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(fato1.predict(), columns = R.columns, index = R.index)\n",
    "\n",
    "df.iloc[:1,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "      <th>Filme_9</th>\n",
       "      <th>Filme_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_0      5.0      3.0      4.0      3.0      3.0      5.0      4.0   \n",
       "\n",
       "        Filme_8  Filme_9  Filme_10  \n",
       "User_0      1.0      5.0       3.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.iloc[:1,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que temos sim algum erro mais notável, como no Filme_8, porem a grande maioria ta com esses muito pequenos, se as notas forem arredondadas (já que teoricamente as notas são sempre números natuais), teriamos um grande número de acertos.\n",
    "\n",
    "Então muito provavelmente, pela maneira que escolhemos os parâmetros, de maneira que não 'overfitasse' nos dados de validação e de teste, vamos ter excelentes resultados para o sistema de recomendação.\n",
    "\n",
    "Finalizamos aqui o exercício do último módulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
